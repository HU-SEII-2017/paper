\documentclass[pdftex,english,oribibl]{llncs}

%% Spracheinstellungen laden
\usepackage[english]{babel}

%% Schriftart in der Ausgabe/Eingabe
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage[latin1]{inputenc}

%% Zitate
\usepackage[numbers]{natbib}
\bibliographystyle{abbrvnat}
%\bibliographystyle{dinat}
%\bibliographystyle{plainnat}
%\bibliographystyle{splncs}
%% Similar to option "sectionbib" but \refname instead of \bibname
\makeatletter
\renewcommand\bibsection{\section*{\refname\@mkboth{\MakeUppercase{\refname}}{\MakeUppercase{\refname}}}}
\makeatother

%% Index
%\usepackage{makeidx}
%\makeindex

%% PDF Einstellungen
% muss nach natbib geladen werden!
\usepackage{nameref}
\usepackage{varioref}
\usepackage[pdfusetitle,pdftex,colorlinks]{hyperref}
\hypersetup{pdfborder={0 0 0}}
\hypersetup{bookmarksdepth=3}
\hypersetup{bookmarksopen=true}
\hypersetup{bookmarksopenlevel=1}
\hypersetup{bookmarksnumbered=true}
\usepackage{color}
\hypersetup{colorlinks=false}
\usepackage{titling}

\usepackage{listings}
\lstdefinestyle{customjava}{
	basicstyle=\footnotesize\ttfamily,
	keywordstyle=\bfseries\color{green!40!black},
	commentstyle=\itshape\color{purple!40!black},
	identifierstyle=\color{blue},
	stringstyle=\color{orange},
}

\lstset{escapechar=@,style=customjava}

\lstset{
	escapechar=\%,
	language=Tex,
	tabsize=2,
	numbers=left,
	%	frame=tB,
	frame=none,
	framerule=0.1pt,
	basicstyle=\footnotesize,
	framexleftmargin=8mm,
	xleftmargin=0.6cm,
	keywordstyle=\bfseries\color{blue},
	identifierstyle=\bfseries,
	numberstyle=\color[RGB]{0,192,192},
	commentstyle=\it\color[RGB]{0,96,96},
	stringstyle=\rmfamily\slshape\color[RGB]{128,0,0},
	showstringspaces=true
}

\usepackage[linesnumbered,ruled]{algorithm2e}

%\usepackage[section]{tocbibind}

\makeatletter
\gdef\@keywords{}
\def\keywords#1{\gdef\@keywords{#1}}
\gdef\@subtitle{}
\def\subtitle#1{\gdef\@subtitle{#1}}

%% modified from llncs
\renewenvironment{abstract}{%
  \list{}{\advance\topsep by0.35cm\relax\small%
          \leftmargin=1cm%
          \labelwidth=\z@%
          \listparindent=\z@%
          \itemindent\listparindent%
          \rightmargin\leftmargin}%
          \item[\hskip\labelsep\bfseries\abstractname]}{%
  \if!\@keywords!\else{\item[~]\item[\hskip\labelsep\bfseries\keywordname]\@keywords}\fi%
  \endlist}

\AtBeginDocument{%
  \if!\@subtitle!\else\hypersetup{pdfsubject={\@subtitle}}\fi
  \if!\@keywords!\else\hypersetup{pdfkeywords={\@keywords}}\fi
}
\makeatother

% llncs hyperref fix
\makeatletter
\providecommand*{\toclevel@author}{0}
\providecommand*{\toclevel@title}{0}
\makeatother

%% Grafiken
\usepackage[pdftex]{graphicx}
\DeclareGraphicsExtensions{.pdf,.jpg,.png}
\usepackage{subfigure}

%% Mathe
\usepackage{amsmath}
\usepackage{amssymb}

%% Listings
\usepackage{listings}
\lstset{escapechar=\%, frame=tb, basicstyle=\footnotesize}

%% Sonstiges
\newcommand{\TODO}[1]{\par\textcolor{red}{#1}\marginpar{\textcolor{red}{TODO}}}
\newcommand{\TODOX}[1]{\textcolor{red}{#1}\marginpar{\textcolor{red}{TODO}}}
\pagestyle{plain}

% Keine "Schusterjungen"
\clubpenalty = 10000
% Keine "Hurenkinder"
\widowpenalty = 10000 \displaywidowpenalty = 10000

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% BEGIN DOCUMENT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pretitle{%
  \begin{center}\LARGE
  \noindent\includegraphics[height=2.5cm]{figures/logo-se}\hfill{}\includegraphics[height=2.5cm]{figures/logo-uni}\\\vspace{0.5cm}
}
\title{Automated program repair using Astor}
% \subtitle{My (optional) Subtitle}
\author{Philipp Badenhoop, Daniel Bucher, Tim Sikatzki}
\institute{Humboldt University of Berlin\\Department of Computer Science\\12489 Berlin, Germany}
\posttitle{\end{center}}


\begin{document}

\maketitle

\begin{abstract}
Since the development of GenProg in 2009, research in automated program repair has made quite some progress. Astor, a Java platform for multiple patch generation tools, is one of the outcomes that we analyzed in more detail, especially its GenProg implementation. 
We discovered that the repair program was not able cope with enums.
Therefore, we provided a reasonable fix to this problem. Although we haven't been able to show that our modified version could find more patches than the original one when being applied to real life open source projects, at least it proved not to fall behind.

\end{abstract}

\section{Introduction}
Automated program repair is still in its infancy.
Although some approaches are able to find reasonable patches for certain bugs, they fail when being applied to larger, real life programs.
Therefore, we share the opinion that there's lots of potential and so we contributed to this research.
Our tool of choice was Astor.
The author's intention was to create a framework for automated program algorithms.
By default, Astor implements three famous repair approaches: GenProg, Kali and MutRepair.
In our research, we mainly focused on GenProg which had the first major impact on automated patch generation.
While working with the GenProg mode, we discovered a bug in Astor. 
Its fix could potentially result in the fact that Astor finds many more patches in buggy software systems than it was able to before.
Our contribution is to provide a reasonable fix for the bug we discovered and to analyze how our new version performs when being applied to famous open source projects.

\section{Background}\label{sec:background}

In our work, we focused on using Astors GenProg mode.
GenProg uses genetic programming to find its repairs \cite{Philipp}.
It takes a program as well as a test suite with positive and negative test cases as input.
Positive test cases correspond to the specification of program behavior which should be kept after applying the patch whereas negative test cases induce the failure.
The tool operates at the level of statements and transforms the input program into an abstract syntax tree.
GenProg performs fault localization by only looking at the statements along the execution path of the negative test cases.
It applies modifications to the program by using its mutation operator which is discussed in more detail in section~\ref{sec:problem}.
Program variants may run through multiple generations until a candidate patch is found which passes the entire test suite. For further informations, see \cite{GenProgPaper}.

\section{Problem}\label{sec:problem}

We created a very simple program which we actually expected Astors GenProg mode to be able to repair.
The program is shown in Figure~\ref{fig:testProgram}.
$getLanguage()$ is the method containing the bug.
Note that we provided a correct implementation of this method in $working()$ which is located in the same class.
Our $getLanguage()$ method should return an enum reference of type Language (see Figure~\ref{fig:enum}) according to the input string $lang$.
The difference between the two methods is that $getLanguage()$ returns $Language.JAVA$ if $lang$ does not equal to either ``C'' or ``CPP'' whereas $working()$ returns $Language.PYTHON$ if $lang$ does not equal to either ``C'', ``CPP'' or ``JAVA''.

\begin{figure}
	\begin{center}
		\lstinputlisting[language=Java]{code/Program.java}
	\end{center}
	\caption{The buggy program. The method $working()$ is the correct implementation of the buggy method $getLanguage()$ which is to be repaired.}
	\label{fig:testProgram}
\end{figure}

\begin{figure}
	\begin{center}
		\lstinputlisting[language=Java]{code/Language.java}
	\end{center}
	\caption{The enum $Language$.}
	\label{fig:enum}
\end{figure}

Since GenProg evaluates its variants using a test suite, Figure~\ref{fig:testsuite} shows the one we created for our buggy program. It contains three positive test cases $p1()$, $p2()$ and $p3()$ and one negative test case $n1()$. 
In the context of automated program repair, positive test cases represent the desired behavior which should be kept after applying the patch whereas negative test cases trigger the bug.
So in our example, $n1()$ triggers our buggy method $getLanguage()$ to return $Language.JAVA$ although we would expect it to output $Language.PYTHON$ using the correct version.

\begin{figure}
\begin{center}
\lstinputlisting[language=Java]{code/ProgramTest.java}
\end{center}
\caption{The test suite.}
\label{fig:testsuite}
\end{figure}

Why are we so confident that GenProg would be able to fix our bug?
To reason about our consciousness, one must understand how GenProg finds its patches.
The repair tool makes use of an evolutionary approach called genetic programming and operates on the level of statements. Its mutation operator selects a statement $stmt$ along the execution path of the negative test case and chooses one of the following actions \cite{Philipp}:
\begin{itemize}
 	\item A statement from anywhere in the program is inserted after $stmt$.
 	\item A statement from anywhere in the program is swapped with $stmt$.
 	\item $stmt$ is deleted.
\end{itemize}
This means that in order to create a patch of our buggy program, the following mutations have to be applied:
\begin{enumerate}
	\item Remove statement ``return Language.JAVA''.
	\item Insert statement ``if(lang.equals("JAVA") return Language.JAVA; else return Language.PYTHON);'' from $working()$ to the place of the statement we just removed in step 1.
\end{enumerate}
We've run Astors GenProg mode and were surprised that it was not able to find a patch.

\section{Solution}\label{sec:solution}

Since Astor failed at repairing our program, during an intense debugging session, we investigated what the tool is doing.
We found out that there was a problem with the $fitInContext()$ method in the class $VariableResolver$. As the name indicates, it checks if a statement fits in some context. For instance, it's called when GenProg wants to insert a statement from somewhere in the code to a place along the execution path of the negative test case. In this situation, the statement to be inserted may contain access to variables which don't appear in the context where it is going to be inserted. Therefore, $fitInContext()$ is used to avoid the creation of uncompilable program variants.

Figure~\ref{fig:fitInContext} gives pseudocode of our fixed version of the method.
Essentially, we only added the check ``$\vee access.isEnumReference()$'' in line 3 to fix the problem.
The algorithm takes a statement $stmt$ and a set of variables as input.
The variables represent the context in which $stmt$ has to fit (e.g. local and/or member variables). At first, we collect all variable accesses which appear in $stmt$.
Every access must also be valid in the destination context which is checked in the for loop.
We consider two types of accesses: those which are \emph{context dependent} and those which are \emph{context independent}. 
An access is context independent if one of the following conditions hold:
\begin{enumerate}
	\item The declaration of the accessed variable is contained inside $stmt$ itself.
	\item The accessed variable is static.
	\item The accessed variable is an enum field.
\end{enumerate}
If the access is not context independent, we check if there exist a variable in the destination context which matches type and identifier with the accessed variable.
The original version did not check the access to be an enum field.
As a consequence, no statement containing an enum reference could be inserted anywhere since $fitInContext()$ always mistakenly returned false.
After applying our fix in Astor, the tool was able to generated the expected patch (see Figure~\ref{fig:fixed}).

\begin{figure}
	\centering
\begin{algorithm}[H]
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}

\Input{Set of context variables $varContext$.}
\Input{Statement $stmt$.}

$varAccesses = collectVariableAccesses(stmt)$\;

\ForAll{$access \in varAccesses$}
{
 $contextIndependend = stmt.contains(access.getDeclaration()) \vee access.isStatic() \vee access.isEnumReference()$ \;

 \If{$\neg contextIndependend \wedge \neg varContext.contains(access)$}
 {
   \Return false\;
 }
}

\Return true\;

\caption{VariableResolver.fitInContext()}
\end{algorithm}
\caption{Pseudocode for our fixed version of the VariableResolver.fitInContext() method.}
\label{fig:fitInContext}
\end{figure}

\begin{figure}
\begin{center}
\lstinputlisting[language=Java]{code/fixed.java}
\end{center}
\caption{The repair of the $getLanguage()$ method produced by our fixed version of Astor.}
\label{fig:fixed}
\end{figure}

\section{Evaluation}\label{sec:evaluation}
To evaluate our modifications, we used the bug database Defects4J which contains 395 bugs of real life open source projects. 
Since running a patch generation tool on large sized projects is very time consuming, we only picked a subset in Defects4J, containing 65 bugs of the Lang project. 
This project seemed to be interesting since none of Astors repair modes was able to find any patches in Astors publication (see \cite{AstorPaper}).

After running Defects4J on both the original Astor and our fixed version, we found out that the programs were behaving exactly the same. Unfortunately, we were not able to generate more patches for the bugs in Defects4J.
This may have several reasons: 
\begin{itemize}
	\item The search space is too large. Since GenProg randomly inserts statements from anywhere in the program using its mutation operator, when being applied to a larger project, the chances of choosing ``the right statements'' is quite low in general.
	\item In the case of our Defects4J bugs, a correct patch is simply not possible to create by just inserting code that contains enum references.
\end{itemize}
Since our Astor version was able to pass all unit tests and found the exact same patches for the example bugs, we are confident that it is at least as stable as the original version. Although we couldn't prove it for real life applications, the generated patch for our own test program in section~\ref{sec:problem} shows that there is definitely some improvement to the tool.

\section{Conclusions}\label{sec:conclusions}

Developing automated program repair tools proved not to be easy - neither in terms of creating new repair approaches nor in terms of the actual implementation. In our situation, forgetting a simple border case by not checking for enum references resulted in the fact that our trivial test program couldn't be fixed. 
Since we showed that our modifications turn out to be reasonable, we're sure that there exists projects which could profit from our fixed Astor version. 

\bibliography{Report-Astor}







\end{document}
